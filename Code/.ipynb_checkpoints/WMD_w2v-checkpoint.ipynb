{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import sklearn as sk\n",
    "from sklearn.metrics import *\n",
    "from nltk import word_tokenize\n",
    "from collections import Counter\n",
    "from gensim.models import word2vec \n",
    "from nltk.corpus import stopwords\n",
    "from keras.models import Sequential\n",
    "from gensim.similarities import WmdSimilarity\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras.layers import Dense, Activation,LSTM,Embedding\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_w2v(filename, w2v_model):\n",
    "    lines = []\n",
    "    with open(filename,\"rb\") as f:\n",
    "        while 1:\n",
    "            try:\n",
    "                lines.append(pickle.load(f))\n",
    "            except EOFError:\n",
    "                break\n",
    "    dicts = []\n",
    "    labels = []\n",
    "    for line in lines:\n",
    "        d = {}\n",
    "        for word in line[0].split():\n",
    "            if word in w2v_model.wv:\n",
    "                w2v_arr = w2v_model.wv[word]\n",
    "                for i in range(0,len(w2v_arr)):\n",
    "                    d['w2v_'+ word + '_' + str(i)] = w2v_arr[i]\n",
    "        dicts.append(d)\n",
    "        labels.append(line[1])\n",
    "    return dicts, np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_features(filename):\n",
    "    vector = []\n",
    "    with open(filename,\"rb\") as f:\n",
    "        while 1:\n",
    "            try:\n",
    "                vector.append(pickle.load(f))\n",
    "            except EOFError:\n",
    "                break\n",
    "    dicts = []\n",
    "    labels = []\n",
    "    for v in vector:\n",
    "        dicts.append(v[0])\n",
    "        labels.append(v[1])\n",
    "    return dicts, np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "brown = nltk.corpus.brown\n",
    "w2v_model = word2vec.Word2Vec(brown.sents(), workers=3, size=50)\n",
    "#w2v_model = word2vec.Word2Vec.load(\"w2v_model_proj\")\n",
    "#X_features_val, y_val = read_features(\"dev_set.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec = DictVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_features_train, y_train = make_w2v(\"train_set.pkl\",w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70732, 603850) (70732,)\n"
     ]
    }
   ],
   "source": [
    "X_train = vec.fit_transform(X_features_train)\n",
    "print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7207, 603850) (7207,)\n"
     ]
    }
   ],
   "source": [
    "X_features_val, y_val = make_w2v(\"dev_set.pkl\",w2v_model)\n",
    "X_val = vec.transform(X_features_val)\n",
    "print(X_val.shape,y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8485, 603850) (8485,)\n"
     ]
    }
   ],
   "source": [
    "X_features_test, y_test = make_w2v(\"test_set.pkl\",w2v_model)\n",
    "X_test = vec.transform(X_features_test)\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Accuracy 0.569855428671\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.60      0.69      6562\n",
      "          1       0.28      0.53      0.36      1923\n",
      "\n",
      "avg / total       0.69      0.58      0.62      8485\n",
      "\n",
      "\n",
      "Precision of Correct Answer:  0.278711098871\n",
      "\n",
      "Recall of Correct Answer:  0.526261050442\n",
      "\n",
      "f1_score of Correct Answer:  0.364422038171\n",
      "\n",
      "confusion_matrix\n",
      "[[3943 2619]\n",
      " [ 911 1012]]\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "clf = LogisticRegression(random_state=2,C=0.1,class_weight=\"balanced\",penalty='l1')\n",
    "clf.fit(X_train,y_train)\n",
    "acc = cross_val_score(clf,X_train,y_train,cv=10)\n",
    "print(\"Average Training Accuracy\",np.mean(acc))\n",
    "y_pred = clf.predict(X_test)\n",
    "\"\"\"\n",
    "y_proba = clf.predict_proba(X_test)\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] == 1:\n",
    "        print(X_features_test[i], y_test[i], y_proba[i][1])\n",
    "\"\"\"\n",
    "print(sk.metrics.classification_report(y_test,y_pred))\n",
    "print (\"\\nPrecision of Correct Answer: \", sk.metrics.precision_score(y_test, y_pred))\n",
    "print (\"\\nRecall of Correct Answer: \", sk.metrics.recall_score(y_test, y_pred))\n",
    "print (\"\\nf1_score of Correct Answer: \", sk.metrics.f1_score(y_test, y_pred))\n",
    "print (\"\\nconfusion_matrix\")\n",
    "print (sk.metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Error Analysis\n",
    "for i,y in enumerate(y_pred):\n",
    "    print(X_features_test[i])\n",
    "    if y == 1:\n",
    "        print(\"True\")\n",
    "    else:\n",
    "        print(\"False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#MLP Classifier\n",
    "clf = MLPClassifier(random_state=1, solver=\"lbfgs\", hidden_layer_sizes=(2,1))\n",
    "clf.fit(X_train,y_train)\n",
    "acc = cross_val_score(clf,X_train,y_train,cv=10)\n",
    "print(\"Average Training Accuracy\",np.mean(acc))\n",
    "y_pred = clf.predict(X_test)\n",
    "print(sk.metrics.classification_report(y_test,y_pred))\n",
    "print (\"\\nPrecision of Correct Answer: \", sk.metrics.precision_score(y_test, y_pred))\n",
    "print (\"\\nRecall of Correct Answer: \", sk.metrics.recall_score(y_test, y_pred))\n",
    "print (\"\\nf1_score of Correct Answer: \", sk.metrics.f1_score(y_test, y_pred))\n",
    "print (\"\\nconfusion_matrix\")\n",
    "print (sk.metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_features_train, y_train1 = read_features(\"train_set.pkl\")\n",
    "X_train1 = vec.fit_transform(X_features_train)\n",
    "print(X_train1.shape,y_train1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_features_test, y_test1 = read_features(\"test_set.pkl\")\n",
    "X_test1 = vec.transform(X_features_test)\n",
    "print(X_test1.shape,y_test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "####### Keras sequential method ##########\n",
    "##########################################\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "X_train = X_train1.toarray()\n",
    "X_test = X_test1.toarray()\n",
    "\n",
    "\n",
    "y_true = y_test1\n",
    "\n",
    "y_train = to_categorical(y_train1)\n",
    "y_test = to_categorical(y_test1)\n",
    "\n",
    "print(len(X_train),len(y_train),len(X_test),len(y_test))\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(20,input_dim=X_train.shape[1]))\n",
    "model.add(Activation('relu'))\n",
    "#print(model.output_shape)\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
    "model.fit(X_train[:25000],y_train[:25000],epochs=2)\n",
    "loss_metrics=model.evaluate(X_test,y_test)\n",
    "classes=model.predict(X_test)\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "\n",
    "y_pred = [np.argmax(c) for c in classes]\n",
    "print(Counter([np.argmax(c) for c in classes]))\n",
    "print(classification_report(y_true,y_pred))\n",
    "print(\"\\nPrecision\", sk.metrics.precision_score(y_true, y_pred))\n",
    "print(\"\\nRecall\", sk.metrics.recall_score(y_true, y_pred))\n",
    "print(\"\\nf1_score\", sk.metrics.f1_score(y_true, y_pred))\n",
    "print(\"\\nconfusion_matrix\")\n",
    "print(sk.metrics.confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "######## Keras LSTM method ############\n",
    "#######################################\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Embedding(X_train.shape[1],output_dim=2))\n",
    "model.add(LSTM(10,input_dim=X_train.shape[1]))\n",
    "model.add(Activation('relu'))\n",
    "print(model.output_shape)\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='sgd',metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train[:2500],y_train[:2500],epochs=1)\n",
    "loss_metrics=model.evaluate(X_test,y_test)\n",
    "classes=model.predict(X_test)\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
